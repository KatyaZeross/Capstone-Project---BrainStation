{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAwIhQ1hDEhA"
   },
   "source": [
    "# Capstone Project: Star Trek IMDB Ratings Predictor - Katya Kogan\n",
    "--- \n",
    "## Part 2\n",
    "\n",
    "Now we've successfully cleaned and prepared our data, we can begin our modelling process to determine if the characters (by their spoken parts) contribute to the `imdbRating`. \n",
    "\n",
    "Since we are focusing on feature importance, our models will have to be carefully chosen. (INSERT MORE INFO HERE AFTER MODELLING)\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- Random Forest\n",
    "- AdaBoost\n",
    "- Gradient Boost Tree \n",
    "\n",
    "We'll begin by importing all the relevant libraries needed for our project. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "utq29HioCs5x"
   },
   "outputs": [],
   "source": [
    "# import the relevant libraries needed \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "# Ml libraries \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# libraries for splitting and converting text into numerical data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model as lm, metrics, tree, ensemble, model_selection as ms, feature_selection, svm\n",
    "# Ignore futurewarnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIAb7bKrFhyg"
   },
   "source": [
    "Now we've imported our libraries relevant to our needs, we'll begin by importing our dataset, some minor EDA and prep before getting into the nitty gritty for our models. \n",
    "\n",
    "Let's take a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kvVWapLvGMBN"
   },
   "outputs": [],
   "source": [
    "# # uploading files into colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "foDeCZ3CCti8",
    "outputId": "0e984f1f-8522-4ed2-8a53-aff0629e00aa"
   },
   "outputs": [],
   "source": [
    "# reading in the dataframe \n",
    "# import io\n",
    "ST_df = pd.read_csv(r\"C:\\Users\\Katya\\Documents\\GitHub\\Capstone-Project---BrainStation\\StarTrek_Prepped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7gm9ZoabGdOh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>EPISODE</th>\n",
       "      <th>PICARD_PCT</th>\n",
       "      <th>RIKER_PCT</th>\n",
       "      <th>DATA_PCT</th>\n",
       "      <th>WORF_PCT</th>\n",
       "      <th>TROI_PCT</th>\n",
       "      <th>BEVERLY_PCT</th>\n",
       "      <th>GEORDI_PCT</th>\n",
       "      <th>Q_PCT</th>\n",
       "      <th>LORE_PCT</th>\n",
       "      <th>WESLEY_PCT</th>\n",
       "      <th>GUINAN_PCT</th>\n",
       "      <th>TOTAL_WORDS</th>\n",
       "      <th>SCRIPT</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11001001</td>\n",
       "      <td>37.54</td>\n",
       "      <td>35.56</td>\n",
       "      <td>11.34</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2725.0</td>\n",
       "      <td>captains log stardate 9 the enterprise has be...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a fistful of datas</td>\n",
       "      <td>12.89</td>\n",
       "      <td>3.38</td>\n",
       "      <td>16.98</td>\n",
       "      <td>28.58</td>\n",
       "      <td>16.79</td>\n",
       "      <td>4.76</td>\n",
       "      <td>16.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>captains log stardate  the enterprise has ent...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a matter of honor</td>\n",
       "      <td>27.73</td>\n",
       "      <td>44.49</td>\n",
       "      <td>8.21</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>we are approaching starbase onesevennine,  ha...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a matter of perspective</td>\n",
       "      <td>39.17</td>\n",
       "      <td>26.08</td>\n",
       "      <td>10.39</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2811.0</td>\n",
       "      <td>we have arrived at tanuga four captain the aw...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a matter of time</td>\n",
       "      <td>37.49</td>\n",
       "      <td>10.42</td>\n",
       "      <td>20.31</td>\n",
       "      <td>6.02</td>\n",
       "      <td>2.68</td>\n",
       "      <td>6.30</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2841.0</td>\n",
       "      <td>captains log stardate  the enterprise is on i...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  EPISODE  PICARD_PCT  RIKER_PCT  DATA_PCT  \\\n",
       "0           0                 11001001       37.54      35.56     11.34   \n",
       "1           1       a fistful of datas       12.89       3.38     16.98   \n",
       "2           2        a matter of honor       27.73      44.49      8.21   \n",
       "3           3  a matter of perspective       39.17      26.08     10.39   \n",
       "4           4         a matter of time       37.49      10.42     20.31   \n",
       "\n",
       "   WORF_PCT  TROI_PCT  BEVERLY_PCT  GEORDI_PCT  Q_PCT  LORE_PCT  WESLEY_PCT  \\\n",
       "0      1.98      0.00         4.99        5.25    0.0       0.0        3.34   \n",
       "1     28.58     16.79         4.76       16.64    0.0       0.0        0.00   \n",
       "2      8.95      0.00         0.00        0.00    0.0       0.0       10.62   \n",
       "3      1.64      3.34         1.00       15.55    0.0       0.0        2.85   \n",
       "4      6.02      2.68         6.30       16.79    0.0       0.0        0.00   \n",
       "\n",
       "   GUINAN_PCT  TOTAL_WORDS                                             SCRIPT  \\\n",
       "0         0.0       2725.0   captains log stardate 9 the enterprise has be...   \n",
       "1         0.0       2103.0   captains log stardate  the enterprise has ent...   \n",
       "2         0.0       2279.0   we are approaching starbase onesevennine,  ha...   \n",
       "3         0.0       2811.0   we have arrived at tanuga four captain the aw...   \n",
       "4         0.0       2841.0   captains log stardate  the enterprise is on i...   \n",
       "\n",
       "   RATING  \n",
       "0       8  \n",
       "1       8  \n",
       "2       8  \n",
       "3       7  \n",
       "4       7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "ST_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_EKix33G3_H"
   },
   "source": [
    "Now we've successfully imported our dataframe, we can see that there is still some minor cleaning to do. We'll have to drop the `Unnamed: 0` column. \n",
    "\n",
    "But first, drop the `Unnamed: 0` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bIofsIcGGmxp"
   },
   "outputs": [],
   "source": [
    "# dropping the Unnamed: 0 column\n",
    "ST_df.drop(labels='Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TJ1kdJeKHjoR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EPISODE</th>\n",
       "      <th>PICARD_PCT</th>\n",
       "      <th>RIKER_PCT</th>\n",
       "      <th>DATA_PCT</th>\n",
       "      <th>WORF_PCT</th>\n",
       "      <th>TROI_PCT</th>\n",
       "      <th>BEVERLY_PCT</th>\n",
       "      <th>GEORDI_PCT</th>\n",
       "      <th>Q_PCT</th>\n",
       "      <th>LORE_PCT</th>\n",
       "      <th>WESLEY_PCT</th>\n",
       "      <th>GUINAN_PCT</th>\n",
       "      <th>TOTAL_WORDS</th>\n",
       "      <th>SCRIPT</th>\n",
       "      <th>RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11001001</td>\n",
       "      <td>37.54</td>\n",
       "      <td>35.56</td>\n",
       "      <td>11.34</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2725.0</td>\n",
       "      <td>captains log stardate 9 the enterprise has be...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a fistful of datas</td>\n",
       "      <td>12.89</td>\n",
       "      <td>3.38</td>\n",
       "      <td>16.98</td>\n",
       "      <td>28.58</td>\n",
       "      <td>16.79</td>\n",
       "      <td>4.76</td>\n",
       "      <td>16.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2103.0</td>\n",
       "      <td>captains log stardate  the enterprise has ent...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a matter of honor</td>\n",
       "      <td>27.73</td>\n",
       "      <td>44.49</td>\n",
       "      <td>8.21</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2279.0</td>\n",
       "      <td>we are approaching starbase onesevennine,  ha...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a matter of perspective</td>\n",
       "      <td>39.17</td>\n",
       "      <td>26.08</td>\n",
       "      <td>10.39</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2811.0</td>\n",
       "      <td>we have arrived at tanuga four captain the aw...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a matter of time</td>\n",
       "      <td>37.49</td>\n",
       "      <td>10.42</td>\n",
       "      <td>20.31</td>\n",
       "      <td>6.02</td>\n",
       "      <td>2.68</td>\n",
       "      <td>6.30</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2841.0</td>\n",
       "      <td>captains log stardate  the enterprise is on i...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   EPISODE  PICARD_PCT  RIKER_PCT  DATA_PCT  WORF_PCT  \\\n",
       "0                 11001001       37.54      35.56     11.34      1.98   \n",
       "1       a fistful of datas       12.89       3.38     16.98     28.58   \n",
       "2        a matter of honor       27.73      44.49      8.21      8.95   \n",
       "3  a matter of perspective       39.17      26.08     10.39      1.64   \n",
       "4         a matter of time       37.49      10.42     20.31      6.02   \n",
       "\n",
       "   TROI_PCT  BEVERLY_PCT  GEORDI_PCT  Q_PCT  LORE_PCT  WESLEY_PCT  GUINAN_PCT  \\\n",
       "0      0.00         4.99        5.25    0.0       0.0        3.34         0.0   \n",
       "1     16.79         4.76       16.64    0.0       0.0        0.00         0.0   \n",
       "2      0.00         0.00        0.00    0.0       0.0       10.62         0.0   \n",
       "3      3.34         1.00       15.55    0.0       0.0        2.85         0.0   \n",
       "4      2.68         6.30       16.79    0.0       0.0        0.00         0.0   \n",
       "\n",
       "   TOTAL_WORDS                                             SCRIPT  RATING  \n",
       "0       2725.0   captains log stardate 9 the enterprise has be...       8  \n",
       "1       2103.0   captains log stardate  the enterprise has ent...       8  \n",
       "2       2279.0   we are approaching starbase onesevennine,  ha...       8  \n",
       "3       2811.0   we have arrived at tanuga four captain the aw...       7  \n",
       "4       2841.0   captains log stardate  the enterprise is on i...       7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "ST_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhH0jWvKHr4B"
   },
   "source": [
    "Great, we've successfully dropped the unnecessary column. Now, let's take a closer look at the `RATING` distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DHEuB0ujHkG_"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at the distribution of the IMDB Ratings\n",
    "values, counts = np.unique(ST_df['RATING'], return_counts=True)\n",
    "normalized_reviews = counts/counts.sum()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(values, normalized_reviews * 100, edgecolor='black', color='#002193')\n",
    "plt.xlabel('imdbRating')\n",
    "plt.ylabel('% of Reviews')\n",
    "sns.despine()\n",
    "plt.title(\"IMDB Ratings Distribution\")\n",
    "plt.savefig(\"IMDB Ratings Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DR-JChcbJd3n"
   },
   "source": [
    "We can see that the distribution is normal, with a slight skew to the left. More than 30% of the total reviews are above a rating of 7 or higher. \n",
    "\n",
    "Our next step is to OneHotEncode the `EPISODE` column as it is not contributing to our model properly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(ST_df[['EPISODE']])\n",
    "    res = pd.concat([ST_df, dummies], axis=1)\n",
    "    res = res.drop(['EPISODE'], axis=1)\n",
    "    return(res) \n",
    "\n",
    "ST_df = encode_and_bind(ST_df, 'EPISODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PICARD_PCT</th>\n",
       "      <th>RIKER_PCT</th>\n",
       "      <th>DATA_PCT</th>\n",
       "      <th>WORF_PCT</th>\n",
       "      <th>TROI_PCT</th>\n",
       "      <th>BEVERLY_PCT</th>\n",
       "      <th>GEORDI_PCT</th>\n",
       "      <th>Q_PCT</th>\n",
       "      <th>LORE_PCT</th>\n",
       "      <th>WESLEY_PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>EPISODE_unification part 1</th>\n",
       "      <th>EPISODE_unification part 2</th>\n",
       "      <th>EPISODE_up the long ladder</th>\n",
       "      <th>EPISODE_violations</th>\n",
       "      <th>EPISODE_we'll always have paris</th>\n",
       "      <th>EPISODE_when the bough breaks</th>\n",
       "      <th>EPISODE_where no one has gone before</th>\n",
       "      <th>EPISODE_where silence has lease</th>\n",
       "      <th>EPISODE_who watches the watchers</th>\n",
       "      <th>EPISODE_yesterday's enterprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.54</td>\n",
       "      <td>35.56</td>\n",
       "      <td>11.34</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.89</td>\n",
       "      <td>3.38</td>\n",
       "      <td>16.98</td>\n",
       "      <td>28.58</td>\n",
       "      <td>16.79</td>\n",
       "      <td>4.76</td>\n",
       "      <td>16.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.73</td>\n",
       "      <td>44.49</td>\n",
       "      <td>8.21</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.17</td>\n",
       "      <td>26.08</td>\n",
       "      <td>10.39</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.49</td>\n",
       "      <td>10.42</td>\n",
       "      <td>20.31</td>\n",
       "      <td>6.02</td>\n",
       "      <td>2.68</td>\n",
       "      <td>6.30</td>\n",
       "      <td>16.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PICARD_PCT  RIKER_PCT  DATA_PCT  WORF_PCT  TROI_PCT  BEVERLY_PCT  \\\n",
       "0       37.54      35.56     11.34      1.98      0.00         4.99   \n",
       "1       12.89       3.38     16.98     28.58     16.79         4.76   \n",
       "2       27.73      44.49      8.21      8.95      0.00         0.00   \n",
       "3       39.17      26.08     10.39      1.64      3.34         1.00   \n",
       "4       37.49      10.42     20.31      6.02      2.68         6.30   \n",
       "\n",
       "   GEORDI_PCT  Q_PCT  LORE_PCT  WESLEY_PCT  ...  EPISODE_unification part 1  \\\n",
       "0        5.25    0.0       0.0        3.34  ...                           0   \n",
       "1       16.64    0.0       0.0        0.00  ...                           0   \n",
       "2        0.00    0.0       0.0       10.62  ...                           0   \n",
       "3       15.55    0.0       0.0        2.85  ...                           0   \n",
       "4       16.79    0.0       0.0        0.00  ...                           0   \n",
       "\n",
       "   EPISODE_unification part 2 EPISODE_up the long ladder  EPISODE_violations  \\\n",
       "0                           0                          0                   0   \n",
       "1                           0                          0                   0   \n",
       "2                           0                          0                   0   \n",
       "3                           0                          0                   0   \n",
       "4                           0                          0                   0   \n",
       "\n",
       "   EPISODE_we'll always have paris  EPISODE_when the bough breaks  \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "\n",
       "   EPISODE_where no one has gone before  EPISODE_where silence has lease  \\\n",
       "0                                     0                                0   \n",
       "1                                     0                                0   \n",
       "2                                     0                                0   \n",
       "3                                     0                                0   \n",
       "4                                     0                                0   \n",
       "\n",
       "   EPISODE_who watches the watchers  EPISODE_yesterday's enterprise  \n",
       "0                                 0                               0  \n",
       "1                                 0                               0  \n",
       "2                                 0                               0  \n",
       "3                                 0                               0  \n",
       "4                                 0                               0  \n",
       "\n",
       "[5 rows x 187 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ST_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll convert the `RATING` column to binary, where values above the rating of 7 will receive a 1, and the rest, 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where reviews that are below 9 should be encoded as 0 ('not good') and reviews with scores 9 and 10 as 1 ('good').\n",
    "ST_df['RATING'] = np.where(ST_df['RATING'] > 7, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance: [0.54 0.46]\n"
     ]
    }
   ],
   "source": [
    "# count the unique values and the number of times they appear\n",
    "values, counts = np.unique(ST_df['RATING'], return_counts=True)\n",
    "\n",
    "# normalize the counts to bring them into the same range (o and 1)\n",
    "normalized_counts = counts/counts.sum()\n",
    "\n",
    "# instantiate the plot\n",
    "plt.figure()\n",
    "\n",
    "# create a bar plot and convert the normalized_counts to percentage \n",
    "plt.bar([\"Less than 7\", \"Greater than 7\"], normalized_counts*100, edgecolor='black', color='indigo') \n",
    "\n",
    "# relevant labels\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('% of Reviews')\n",
    "plt.title('Class Imbalance of Ratings')\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "# print the distribution of class imbalance\n",
    "print(f\"Class imbalance: {np.round(normalized_counts, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUjxWqCONxAO"
   },
   "source": [
    "The class imbalance is fair, since the distribution of the ratings was normal - we can trust that an imbalance of 54/46 is close enough to model on. \n",
    "\n",
    "Moving on, we can be confident going ahead with splitting the data set into train and test sets for our vectorization of the `RATING` column into numerical datatypes.\n",
    "\n",
    "Before even attempting to vectorize the `RATING` column, we need to split the set into training and testing sets. After the splitting is completed, the training set(s) will be fit and transformed. Sidenote: the testing data shouldn't be mixed with the fit and transformation of the data. The fitting and transformation process will be applied separately to the `RATING` column.\n",
    "\n",
    "Essentially:\n",
    "\n",
    "1. Split `ST_df` into train and test sets\n",
    "2. Apply `CountVectorizer()` on the training set for the `RATING` column\n",
    "3. With the fitted `RATING`, transform the `RATING` column for both X_train and X_test\n",
    "4. Save as a DataFrame\n",
    "5. Combine the transformed `RATING` dataframe with the rest of the numeric columns of the training and test dataset\n",
    "\n",
    "We'll begin by defining our X and y values:\n",
    "\n",
    "X : all columns except for `RATING` (independent)\n",
    "y : contains only `RATING` (dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UM57Gz12Hkyn"
   },
   "outputs": [],
   "source": [
    "# separate df into features and target variable\n",
    "y = ST_df['RATING']\n",
    "# drop the target variable from the X dataframe (remaining features)\n",
    "X = ST_df.drop('RATING',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((173, 186), (173,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've separated the independent and dependent variables from each other, now we'll performing a train test split using a test size of 20% and we won't be using the `y` as the number of classes is already normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 186) (121,)\n",
      "(52, 186) (52,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test size of 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=7)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plXZ_YxQHkpP"
   },
   "source": [
    "Let's the double check the distribution of the classes between the original, training data and the testing data to make sure that the stratify parameter is performing as intended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Proportions\n",
      "0    0.543353\n",
      "1    0.456647\n",
      "Name: RATING, dtype: float64 \n",
      "\n",
      "Training Data Proportions\n",
      "0    0.545455\n",
      "1    0.454545\n",
      "Name: RATING, dtype: float64 \n",
      "\n",
      "Testing Data Proportions\n",
      "0    0.538462\n",
      "1    0.461538\n",
      "Name: RATING, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class proportion in the original\n",
    "print(\"Original Data Proportions\")\n",
    "print(y.value_counts()/len(y), '\\n')\n",
    "\n",
    "# class proportion in the training data\n",
    "print(\"Training Data Proportions\")\n",
    "print(y_train.value_counts()/len(y_train), '\\n')\n",
    "\n",
    "# class proportion of the testing data\n",
    "print(\"Testing Data Proportions\")\n",
    "print(y_test.value_counts()/len(y_test), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Data\n",
    "\n",
    "Before even attempting to model our data that we have, we must tokenize the text data. Our text data is in each document is a list of strings combined together (it's grouped by episode, so all of the lines from each episode are condensed in there, separated by a comma). To ensure optimal results, we'll perform some last additional cleaning steps. \n",
    "\n",
    "The `CountVectorizer()` will take the document, and then splits it into separate parts while removing whitespaces, punctuation, and the removal of stopwords as well. In addition to this, the `CountVectorizer()` has a parameter that allows the removel of tokens that appear a few times across the corpus (`min_df`). \n",
    "\n",
    "Firstly, we'll use the `CountVectorizer()`  to transform the text data and then combine with it the main dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Katya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Katya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing/downloading all the relevant packages\n",
    "import nltk\n",
    "nltk.download(\"stopwords\") # our filler words such as: the, and, for\n",
    "nltk.download(\"punkt\") # for punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing more packages\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalizing the Cleaning\n",
    "\n",
    "Now we'll create a tokenizer that removes the stopwords, and the punctuation from our text data. In the previous notebook, we already did the majority of the cleaning needed for it, including setting to lowercase, some punctuation and stopword removal. However, it seems that not all the stopwords were taken care of. To explain this, during our feature engineering in Part 1... this included grouping the text data on the episode level, rather than a few hundred rows dedicated to a single episode. This means that each line is separated by a comma, and some stopwords are left behind.  \n",
    "\n",
    "*Here's an a small example of what it was before, where the text was line by line:*   \n",
    "\n",
    "|who| episode | text |\n",
    "|:----:|:------:|:-----:|\n",
    "| DATA | the measure of a man | i am a sentient being |\n",
    "| MADDOX | the measure of a man | no you are a robot | \n",
    "| RIKER | the measure of a man | data give me your arm |\n",
    "\n",
    "\n",
    "*Our current dataframe, with all the scripts collated in one document, separated by a comma:*\n",
    "\n",
    "| PICARD_PCT | DATA_PCT | EPISODE | SCRIPT |\n",
    "|:----:|:---:|:------------:|:------:|\n",
    "| 53.5 | 29.1 | the measure of a man | i am a sentient being, no you are a robot, data give me your arm |\n",
    "| 35.23 | 9.64 | i borg | i am locutus of borg, the captain seemed not to respond to the nanobots | \n",
    "\n",
    "Let's clean some text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the commas\n",
    "ST_df['SCRIPT'] = ST_df['SCRIPT'].str.replace(r\"[^-9A-Za-z ]\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PICARD_PCT</th>\n",
       "      <th>RIKER_PCT</th>\n",
       "      <th>DATA_PCT</th>\n",
       "      <th>WORF_PCT</th>\n",
       "      <th>TROI_PCT</th>\n",
       "      <th>BEVERLY_PCT</th>\n",
       "      <th>GEORDI_PCT</th>\n",
       "      <th>Q_PCT</th>\n",
       "      <th>LORE_PCT</th>\n",
       "      <th>WESLEY_PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>EPISODE_unification part 1</th>\n",
       "      <th>EPISODE_unification part 2</th>\n",
       "      <th>EPISODE_up the long ladder</th>\n",
       "      <th>EPISODE_violations</th>\n",
       "      <th>EPISODE_we'll always have paris</th>\n",
       "      <th>EPISODE_when the bough breaks</th>\n",
       "      <th>EPISODE_where no one has gone before</th>\n",
       "      <th>EPISODE_where silence has lease</th>\n",
       "      <th>EPISODE_who watches the watchers</th>\n",
       "      <th>EPISODE_yesterday's enterprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>15.20</td>\n",
       "      <td>6.49</td>\n",
       "      <td>15.03</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.04</td>\n",
       "      <td>33.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>51.89</td>\n",
       "      <td>8.26</td>\n",
       "      <td>18.80</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.97</td>\n",
       "      <td>14.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>69.22</td>\n",
       "      <td>9.09</td>\n",
       "      <td>10.23</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>27.34</td>\n",
       "      <td>19.92</td>\n",
       "      <td>4.31</td>\n",
       "      <td>13.72</td>\n",
       "      <td>6.64</td>\n",
       "      <td>14.01</td>\n",
       "      <td>14.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>62.44</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.78</td>\n",
       "      <td>10.62</td>\n",
       "      <td>17.24</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>55.63</td>\n",
       "      <td>16.68</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.40</td>\n",
       "      <td>8.49</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>30.12</td>\n",
       "      <td>11.88</td>\n",
       "      <td>14.19</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.23</td>\n",
       "      <td>28.55</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>38.65</td>\n",
       "      <td>11.47</td>\n",
       "      <td>6.36</td>\n",
       "      <td>29.19</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.50</td>\n",
       "      <td>8.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.14</td>\n",
       "      <td>22.76</td>\n",
       "      <td>1.42</td>\n",
       "      <td>7.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>19.20</td>\n",
       "      <td>36.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>12.85</td>\n",
       "      <td>5.39</td>\n",
       "      <td>22.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.91</td>\n",
       "      <td>9.50</td>\n",
       "      <td>46.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PICARD_PCT  RIKER_PCT  DATA_PCT  WORF_PCT  TROI_PCT  BEVERLY_PCT  \\\n",
       "62        15.20       6.49     15.03      4.86      0.00        25.04   \n",
       "101       51.89       8.26     18.80      1.62      1.78         2.97   \n",
       "153       69.22       9.09     10.23      6.47      0.78         0.00   \n",
       "74        27.34      19.92      4.31     13.72      6.64        14.01   \n",
       "71        62.44       6.72      1.78     10.62     17.24         0.95   \n",
       "171       55.63      16.68      5.29      0.62     10.40         8.49   \n",
       "127       30.12      11.88     14.19      2.23      2.23        28.55   \n",
       "103       38.65      11.47      6.36     29.19      0.68         3.50   \n",
       "8         13.14      22.76      1.42      7.01      0.04        19.20   \n",
       "66        12.85       5.39     22.20      0.47      2.91         9.50   \n",
       "\n",
       "     GEORDI_PCT  Q_PCT  LORE_PCT  WESLEY_PCT  ...  EPISODE_unification part 1  \\\n",
       "62        33.38    0.0       0.0        0.00  ...                           0   \n",
       "101       14.67    0.0       0.0        0.00  ...                           0   \n",
       "153        4.22    0.0       0.0        0.00  ...                           0   \n",
       "74        14.06    0.0       0.0        0.00  ...                           0   \n",
       "71         0.26    0.0       0.0        0.00  ...                           0   \n",
       "171        2.89    0.0       0.0        0.00  ...                           0   \n",
       "127        3.96    0.0       0.0        6.85  ...                           0   \n",
       "103        8.13    0.0       0.0        2.01  ...                           0   \n",
       "8         36.44    0.0       0.0        0.00  ...                           0   \n",
       "66        46.68    0.0       0.0        0.00  ...                           0   \n",
       "\n",
       "     EPISODE_unification part 2 EPISODE_up the long ladder  \\\n",
       "62                            0                          0   \n",
       "101                           0                          0   \n",
       "153                           0                          0   \n",
       "74                            0                          0   \n",
       "71                            0                          0   \n",
       "171                           0                          0   \n",
       "127                           0                          0   \n",
       "103                           0                          0   \n",
       "8                             0                          0   \n",
       "66                            0                          0   \n",
       "\n",
       "     EPISODE_violations  EPISODE_we'll always have paris  \\\n",
       "62                    0                                0   \n",
       "101                   0                                0   \n",
       "153                   0                                0   \n",
       "74                    0                                0   \n",
       "71                    0                                0   \n",
       "171                   0                                0   \n",
       "127                   0                                0   \n",
       "103                   0                                0   \n",
       "8                     0                                0   \n",
       "66                    0                                0   \n",
       "\n",
       "     EPISODE_when the bough breaks  EPISODE_where no one has gone before  \\\n",
       "62                               0                                     0   \n",
       "101                              0                                     0   \n",
       "153                              0                                     0   \n",
       "74                               0                                     0   \n",
       "71                               0                                     0   \n",
       "171                              0                                     0   \n",
       "127                              0                                     0   \n",
       "103                              0                                     0   \n",
       "8                                0                                     0   \n",
       "66                               0                                     0   \n",
       "\n",
       "     EPISODE_where silence has lease  EPISODE_who watches the watchers  \\\n",
       "62                                 0                                 0   \n",
       "101                                0                                 0   \n",
       "153                                0                                 0   \n",
       "74                                 0                                 0   \n",
       "71                                 0                                 0   \n",
       "171                                0                                 1   \n",
       "127                                0                                 0   \n",
       "103                                0                                 0   \n",
       "8                                  0                                 0   \n",
       "66                                 0                                 0   \n",
       "\n",
       "     EPISODE_yesterday's enterprise  \n",
       "62                                0  \n",
       "101                               0  \n",
       "153                               0  \n",
       "74                                0  \n",
       "71                                0  \n",
       "171                               0  \n",
       "127                               0  \n",
       "103                               0  \n",
       "8                                 0  \n",
       "66                                0  \n",
       "\n",
       "[10 rows x 187 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "ST_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 187)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ST_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset successfully cleaned, we'll move ahead with the vectorization of the `SCRIPT` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words with the stop words argument included\n",
    "bagofwords = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# fit the training date for positive review\n",
    "bagofwords.fit(X_train['SCRIPT'])\n",
    "\n",
    "# transform the positive review column for both training and testing data\n",
    "X_train_transformed = bagofwords.transform(X_train['SCRIPT']) \n",
    "X_test_transformed = bagofwords.transform(X_test['SCRIPT']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<121x17739 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 113872 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<52x17739 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45588 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been transformed, now we'll create a single dataframe that contains all the text's bag of words as individual words as the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataframe containing the bag of words as the columnn for each word in X_train\n",
    "script_count = pd.DataFrame(X_train_transformed.todense(), columns=bagofwords.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>99</th>\n",
       "      <th>aaaaard</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aban</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abberation</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zweller</th>\n",
       "      <th>zylo</th>\n",
       "      <th>zytchin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17739 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   99  aaaaard  aaah  aah  aaron  aban  abandon  abandoned  abandoning  \\\n",
       "0   0        0     0    0      0     0        0          0           0   \n",
       "1   0        0     0    0      0     0        0          1           0   \n",
       "2   0        0     0    0      0     0        0          0           0   \n",
       "3   0        0     0    0      0     0        0          0           0   \n",
       "4   0        0     0    0      0     0        0          0           0   \n",
       "\n",
       "   abberation  ...  zip  zipping  zone  zones  zoo  zoology  zorn  zweller  \\\n",
       "0           0  ...    0        0     0      0    0        0     0        0   \n",
       "1           0  ...    0        0     0      0    0        0     0        0   \n",
       "2           0  ...    0        0     0      0    0        0     0        0   \n",
       "3           0  ...    0        0     0      0    0        0     0        0   \n",
       "4           0  ...    0        0     0      0    0        0     0        0   \n",
       "\n",
       "   zylo  zytchin  \n",
       "0     0        0  \n",
       "1     0        0  \n",
       "2     0        0  \n",
       "3     0        0  \n",
       "4     0        0  \n",
       "\n",
       "[5 rows x 17739 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataframe ready to be combined with our main dataframe, we'll use the `concat()` method. After, we'll reset the index (and assign it back to `X_train` and `X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index of the X_train\n",
    "X_train = X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PICARD_PCT</th>\n",
       "      <th>RIKER_PCT</th>\n",
       "      <th>DATA_PCT</th>\n",
       "      <th>WORF_PCT</th>\n",
       "      <th>TROI_PCT</th>\n",
       "      <th>BEVERLY_PCT</th>\n",
       "      <th>GEORDI_PCT</th>\n",
       "      <th>Q_PCT</th>\n",
       "      <th>LORE_PCT</th>\n",
       "      <th>WESLEY_PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>EPISODE_unification part 1</th>\n",
       "      <th>EPISODE_unification part 2</th>\n",
       "      <th>EPISODE_up the long ladder</th>\n",
       "      <th>EPISODE_violations</th>\n",
       "      <th>EPISODE_we'll always have paris</th>\n",
       "      <th>EPISODE_when the bough breaks</th>\n",
       "      <th>EPISODE_where no one has gone before</th>\n",
       "      <th>EPISODE_where silence has lease</th>\n",
       "      <th>EPISODE_who watches the watchers</th>\n",
       "      <th>EPISODE_yesterday's enterprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.49</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.75</td>\n",
       "      <td>7.30</td>\n",
       "      <td>9.37</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.33</td>\n",
       "      <td>16.82</td>\n",
       "      <td>12.25</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.65</td>\n",
       "      <td>15.02</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.26</td>\n",
       "      <td>1.51</td>\n",
       "      <td>44.49</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.14</td>\n",
       "      <td>21.29</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.29</td>\n",
       "      <td>10.25</td>\n",
       "      <td>6.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.38</td>\n",
       "      <td>26.44</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>34.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PICARD_PCT  RIKER_PCT  DATA_PCT  WORF_PCT  TROI_PCT  BEVERLY_PCT  \\\n",
       "0       52.49       6.80      0.00     13.75      7.30         9.37   \n",
       "1       26.33      16.82     12.25      4.25      4.65        15.02   \n",
       "2       18.26       1.51     44.49      1.51      2.17         0.00   \n",
       "3       59.14      21.29      2.72      0.29     10.25         6.31   \n",
       "4       30.38      26.44      3.82      3.88      0.97        34.52   \n",
       "\n",
       "   GEORDI_PCT  Q_PCT  LORE_PCT  WESLEY_PCT  ...  EPISODE_unification part 1  \\\n",
       "0        1.46    0.0       0.0        1.01  ...                           0   \n",
       "1        6.16    0.0       0.0       14.52  ...                           0   \n",
       "2       32.07    0.0       0.0        0.00  ...                           0   \n",
       "3        0.00    0.0       0.0        0.00  ...                           0   \n",
       "4        0.00    0.0       0.0        0.00  ...                           0   \n",
       "\n",
       "   EPISODE_unification part 2 EPISODE_up the long ladder  EPISODE_violations  \\\n",
       "0                           0                          0                   0   \n",
       "1                           0                          0                   0   \n",
       "2                           0                          0                   0   \n",
       "3                           0                          0                   0   \n",
       "4                           0                          0                   0   \n",
       "\n",
       "   EPISODE_we'll always have paris  EPISODE_when the bough breaks  \\\n",
       "0                                0                              0   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              0   \n",
       "\n",
       "   EPISODE_where no one has gone before  EPISODE_where silence has lease  \\\n",
       "0                                     0                                0   \n",
       "1                                     0                                0   \n",
       "2                                     0                                0   \n",
       "3                                     0                                0   \n",
       "4                                     0                                0   \n",
       "\n",
       "   EPISODE_who watches the watchers  EPISODE_yesterday's enterprise  \n",
       "0                                 0                               0  \n",
       "1                                 0                               0  \n",
       "2                                 0                               0  \n",
       "3                                 0                               0  \n",
       "4                                 0                               0  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 186)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the vectorized data with the original X_train\n",
    "X_train = pd.concat([X_train, script_count], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the script column\n",
    "X_train = X_train.drop('SCRIPT', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PICARD_PCT</th>\n",
       "      <th>RIKER_PCT</th>\n",
       "      <th>DATA_PCT</th>\n",
       "      <th>WORF_PCT</th>\n",
       "      <th>TROI_PCT</th>\n",
       "      <th>BEVERLY_PCT</th>\n",
       "      <th>GEORDI_PCT</th>\n",
       "      <th>Q_PCT</th>\n",
       "      <th>LORE_PCT</th>\n",
       "      <th>WESLEY_PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zweller</th>\n",
       "      <th>zylo</th>\n",
       "      <th>zytchin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.49</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.75</td>\n",
       "      <td>7.30</td>\n",
       "      <td>9.37</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.33</td>\n",
       "      <td>16.82</td>\n",
       "      <td>12.25</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.65</td>\n",
       "      <td>15.02</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.26</td>\n",
       "      <td>1.51</td>\n",
       "      <td>44.49</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.14</td>\n",
       "      <td>21.29</td>\n",
       "      <td>2.72</td>\n",
       "      <td>0.29</td>\n",
       "      <td>10.25</td>\n",
       "      <td>6.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.38</td>\n",
       "      <td>26.44</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>34.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17924 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PICARD_PCT  RIKER_PCT  DATA_PCT  WORF_PCT  TROI_PCT  BEVERLY_PCT  \\\n",
       "0       52.49       6.80      0.00     13.75      7.30         9.37   \n",
       "1       26.33      16.82     12.25      4.25      4.65        15.02   \n",
       "2       18.26       1.51     44.49      1.51      2.17         0.00   \n",
       "3       59.14      21.29      2.72      0.29     10.25         6.31   \n",
       "4       30.38      26.44      3.82      3.88      0.97        34.52   \n",
       "\n",
       "   GEORDI_PCT  Q_PCT  LORE_PCT  WESLEY_PCT  ...  zip  zipping  zone  zones  \\\n",
       "0        1.46    0.0       0.0        1.01  ...    0        0     0      0   \n",
       "1        6.16    0.0       0.0       14.52  ...    0        0     0      0   \n",
       "2       32.07    0.0       0.0        0.00  ...    0        0     0      0   \n",
       "3        0.00    0.0       0.0        0.00  ...    0        0     0      0   \n",
       "4        0.00    0.0       0.0        0.00  ...    0        0     0      0   \n",
       "\n",
       "   zoo  zoology  zorn  zweller  zylo  zytchin  \n",
       "0    0        0     0        0     0        0  \n",
       "1    0        0     0        0     0        0  \n",
       "2    0        0     0        0     0        0  \n",
       "3    0        0     0        0     0        0  \n",
       "4    0        0     0        0     0        0  \n",
       "\n",
       "[5 rows x 17924 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've successfully add our tokenized data to the `X_train` data, and we'll repeat the same steps for the `X_test` data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataframe containing the bag of words as the columnn for each word in X_test\n",
    "script_count2 = pd.DataFrame(X_test_transformed.todense(), columns=bagofwords.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index of the X_test\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the vectorized data with the original X_test\n",
    "X_test = pd.concat([X_test, script_count2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the script column\n",
    "X_test = X_test.drop('SCRIPT', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PICARD_PCT</th>\n",
       "      <th>RIKER_PCT</th>\n",
       "      <th>DATA_PCT</th>\n",
       "      <th>WORF_PCT</th>\n",
       "      <th>TROI_PCT</th>\n",
       "      <th>BEVERLY_PCT</th>\n",
       "      <th>GEORDI_PCT</th>\n",
       "      <th>Q_PCT</th>\n",
       "      <th>LORE_PCT</th>\n",
       "      <th>WESLEY_PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zorn</th>\n",
       "      <th>zweller</th>\n",
       "      <th>zylo</th>\n",
       "      <th>zytchin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.16</td>\n",
       "      <td>14.83</td>\n",
       "      <td>13.43</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.46</td>\n",
       "      <td>22.06</td>\n",
       "      <td>11.19</td>\n",
       "      <td>10.98</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.27</td>\n",
       "      <td>3.92</td>\n",
       "      <td>15.57</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.02</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.82</td>\n",
       "      <td>34.24</td>\n",
       "      <td>34.34</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.17</td>\n",
       "      <td>26.08</td>\n",
       "      <td>10.39</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17924 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PICARD_PCT  RIKER_PCT  DATA_PCT  WORF_PCT  TROI_PCT  BEVERLY_PCT  \\\n",
       "0       44.16      14.83     13.43      2.46      0.00         2.62   \n",
       "1       17.46      22.06     11.19     10.98     12.51         0.00   \n",
       "2       53.27       3.92     15.57      3.47      3.02        10.66   \n",
       "3       18.82      34.24     34.34      5.95      0.53         0.00   \n",
       "4       39.17      26.08     10.39      1.64      3.34         1.00   \n",
       "\n",
       "   GEORDI_PCT  Q_PCT  LORE_PCT  WESLEY_PCT  ...  zip  zipping  zone  zones  \\\n",
       "0        4.41    0.0       0.0        3.86  ...    0        0     0      0   \n",
       "1       12.69    0.0       0.0       13.11  ...    0        0     0      0   \n",
       "2       10.10    0.0       0.0        0.00  ...    0        0     0      0   \n",
       "3        5.26    0.0       0.0        0.85  ...    0        0     1      0   \n",
       "4       15.55    0.0       0.0        2.85  ...    0        0     0      0   \n",
       "\n",
       "   zoo  zoology  zorn  zweller  zylo  zytchin  \n",
       "0    0        0     0        0     0        0  \n",
       "1    0        0     0        0     0        0  \n",
       "2    0        0     0        0     0        0  \n",
       "3    0        0     0        0     0        0  \n",
       "4    0        0     0        0     0        0  \n",
       "\n",
       "[5 rows x 17924 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a quick little visualization of the top 20 most words in the series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X_train data shape is: (121, 17739)\n"
     ]
    }
   ],
   "source": [
    "# counts the number of features in the script column\n",
    "words = bagofwords.get_feature_names()\n",
    "\n",
    "# counts how many words in the array \n",
    "word_counts = X_train_transformed.toarray().sum(axis=0)\n",
    "\n",
    "# create a function to plot the most frequent tokens that takes in tokens, the word count and the top 20 words/tokens\n",
    "def plot_most_frequent(words, word_counts, top=20):\n",
    "    words_df = pd.DataFrame({\"token\": words, \n",
    "                             \"count\": word_counts})\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(0.75*top, 5))\n",
    "    words_df.sort_values(by=\"count\", ascending=False).head(top)\\\n",
    "        .set_index(\"token\")\\\n",
    "        .plot(kind=\"bar\", rot=45, ax=ax, edgecolor='black', color='indigo')\n",
    "    sns.despine()\n",
    "    plt.ylabel(\"# of Counts\")\n",
    "    plt.title(\"Most Frequent Tokens\")\n",
    "    plt.savefig(\"Most Frequent Words\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_most_frequent(words, word_counts)\n",
    "print(f\"The X_train data shape is: {X_train_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Workflow \n",
    "\n",
    "Now that we've successfully split the data set into their respective train and test datasets, we can commence comfortably with modelling. \n",
    "\n",
    "Our workflow will be:\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- SVM\n",
    "- Naive Bayes\n",
    "\n",
    "Let's start with the baseline models, determine which ones perform the best and then start tuning the hyperparameters through pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_standard_scaler = StandardScaler()\n",
    "my_standard_scaler = my_standard_scaler.fit(X_train)\n",
    "X_train_ss = my_standard_scaler.transform(X_train)\n",
    "X_test_ss = my_standard_scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training sets: 121 52\n",
      "Length of testing sets: 121 52\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of training sets:\",len(X_train), len(X_test))\n",
    "print(\"Length of testing sets:\",len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.7650781565861339\n",
      "Test Score: 0.14901286014199477\n"
     ]
    }
   ],
   "source": [
    "#Instantiate the model\n",
    "my_linear = LinearRegression()\n",
    "#Fit model\n",
    "my_linear = my_linear.fit(X_train, y_train)\n",
    "\n",
    "# Scoring on original train and test sets\n",
    "print(f'Train Score: {my_linear.score(X_train_ss, y_train)}')\n",
    "print(f'Test Score: {my_linear.score(X_test_ss, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0\n",
      "Test Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "#Instantiate the model\n",
    "my_log = LogisticRegression()\n",
    "#Fit model\n",
    "my_log = my_log.fit(X_train, y_train)\n",
    "\n",
    "# Scoring on original train and test sets\n",
    "print(f'Train Score: {my_log.score(X_train_ss, y_train)}')\n",
    "print(f'Test Score: {my_log.score(X_test_ss, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0\n",
      "Test Score: 0.6730769230769231\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model\n",
    "SVM_model = LinearSVC()\n",
    "# fit the model\n",
    "SVM_model.fit(X_train, y_train)\n",
    "# Scoring on original train and test sets\n",
    "print(f'Train Score: {SVM_model.score(X_train_ss, y_train)}')\n",
    "print(f'Test Score: {SVM_model.score(X_test_ss, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0\n",
      "Test Score: 0.7115384615384616\n"
     ]
    }
   ],
   "source": [
    "# Instatiate our model\n",
    "nbmodel = MultinomialNB()\n",
    "# Fit our model\n",
    "nbmodel.fit(X_train,y_train)\n",
    "# Scoring on original train and test sets\n",
    "print(f'Train Score: {nbmodel.score(X_train_ss, y_train)}')\n",
    "print(f'Test Score: {nbmodel.score(X_test_ss, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder: 0.5454545454545454\n",
      "test: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "# Instantiate\n",
    "my_knn = KNeighborsClassifier()\n",
    "# Fit\n",
    "my_knn.fit(X_train,y_train)\n",
    "# Predict & evaluate\n",
    "train_accuracy = my_knn.score(X_train_ss,y_train)\n",
    "test_accuracy = my_knn.score(X_test_ss,y_test)\n",
    "\n",
    "print('remainder:',train_accuracy)\n",
    "print('test:',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder: 0.7272727272727273\n",
      "test: 0.5192307692307693\n"
     ]
    }
   ],
   "source": [
    "# instatiate the model\n",
    "DT_model = DecisionTreeClassifier()\n",
    "#fit\n",
    "DT_model.fit(X_train, y_train)\n",
    "# Predict & evaluate\n",
    "train_accuracy = DT_model.score(X_train_ss,y_train)\n",
    "test_accuracy = DT_model.score(X_test_ss,y_test)\n",
    "\n",
    "print('remainder:',train_accuracy)\n",
    "print('test:',test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remainder: 0.9917355371900827\n",
      "test: 0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "my_random_forest = RandomForestClassifier()\n",
    "my_random_forest.fit(X_train, y_train)\n",
    "# Predict & evaluate\n",
    "train_accuracy = my_random_forest.score(X_train_ss,y_train)\n",
    "test_accuracy = my_random_forest.score(X_test_ss,y_test)\n",
    "\n",
    "print('remainder:',train_accuracy)\n",
    "print('test:',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the base estimator\n",
    "estimators = [('model', LogisticAT())] \n",
    "#instantiate the pipeline\n",
    "pipe = Pipeline(estimators)\n",
    "#Set up param grid, for LogisticAT, there is only one hyper parameter for us to tune: alpha\n",
    "param_grid = [\n",
    "            {'model': [LogisticAT()],\n",
    "             'model__alpha': [10**i for i in range(-3,3)]} #set the list of alpha to run a grid search\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, \n",
    "                    cv=3) #Using 3 folds cross validation\n",
    "\n",
    "#fit the grid search\n",
    "fittedgrid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fittedgrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-1b1d379702fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfittedgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fittedgrid' is not defined"
     ]
    }
   ],
   "source": [
    "fittedgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 2_StarTrek_Modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
